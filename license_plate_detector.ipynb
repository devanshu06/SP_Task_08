{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXhqHfXLUC-9"
   },
   "source": [
    "# Training the Model for Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BhrsmfX9UC_p",
    "outputId": "0bd4c93b-dc04-4ca4-877b-9f084a03b550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1728 images belonging to 36 classes.\n",
      "Found 216 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './data/train',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        './data/val',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28        batch_size=1,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jy9Ges8McSGl"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IjCdBYrp4EK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dev\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (24,24), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5aaqsHABUwx"
   },
   "outputs": [],
   "source": [
    "class stop_training_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if logs.get('val_acc') is not None and logs.get('val_acc') > 0.992:\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "!rm -rf logs\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KPAtDd_Jp4BP",
    "outputId": "fbdd1ad4-32fd-40b7-eb13-61ed1db14e47",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dev\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "   5/1728 [..............................] - ETA: 1:04 - loss: 3.5453 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0105s vs `on_train_batch_end` time: 0.0179s). Check your callbacks.\n",
      " 729/1728 [===========>..................] - ETA: 11s - loss: 3.5252 - accuracy: 0.0494"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0b8cfc1ebcd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_training_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit_generator(\n\u001b[0m\u001b[0;32m      4\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1941\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1943\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "callbacks = [tensorboard_callback, stop_training_callback()]\n",
    "model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples // batch_size,\n",
    "      validation_data = validation_generator, \n",
    "      validation_steps = validation_generator.samples // batch_size,\n",
    "      epochs = 80, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model.save('licence-plate.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('licence-plate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the plate from Captured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def extract_plate(img): # the function detects and perfors blurring on the number plate.\n",
    "    plate_img = img.copy()\n",
    "    plate = None\n",
    "    #Loads the data required for detecting the license plates from cascade classifier.\n",
    "    plate_cascade = cv2.CascadeClassifier('./indian_license_plate.xml')\n",
    "\n",
    "    # detects numberplates and returns the coordinates and dimensions of detected license plate's contours.\n",
    "    plate_rect = plate_cascade.detectMultiScale(plate_img, scaleFactor = 1.3, minNeighbors = 7)\n",
    "\n",
    "    for (x,y,w,h) in plate_rect:\n",
    "        a,b = (int(0.02*img.shape[0]), int(0.025*img.shape[1])) #parameter tuning\n",
    "        plate = plate_img[y+a:y+h-a, x+b:x+w-b, :]\n",
    "        # finally representing the detected contours by drawing rectangles around the edges.\n",
    "        cv2.rectangle(plate_img, (x,y), (x+w, y+h), (51,51,255), 3)\n",
    "        \n",
    "    return plate_img, plate # returning the processed image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the contours in extracted image of plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Match contours to license plate or character template\n",
    "def find_contours(dimensions, img) :\n",
    "\n",
    "    # Find all contours in the image\n",
    "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Retrieve potential dimensions\n",
    "    lower_width = dimensions[0]\n",
    "    upper_width = dimensions[1]\n",
    "    lower_height = dimensions[2]\n",
    "    upper_height = dimensions[3]\n",
    "    \n",
    "    # Check largest 5 or  15 contours for license plate or character respectively\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
    "    \n",
    "    ii = cv2.imread('contour.jpg')\n",
    "    \n",
    "    x_cntr_list = []\n",
    "    target_contours = []\n",
    "    img_res = []\n",
    "    for cntr in cntrs :\n",
    "        #detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
    "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
    "        \n",
    "        #checking the dimensions of the contour to filter out the characters by contour's size\n",
    "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
    "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
    "\n",
    "            char_copy = np.zeros((44,24))\n",
    "            #extracting each character using the enclosing rectangle's coordinates.\n",
    "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "            \n",
    "            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
    "            plt.imsave('countour_rect.jpg', ii, format='jpg')\n",
    "\n",
    "            # Make result formatted for classification: invert colors\n",
    "            char = cv2.subtract(255, char)\n",
    "\n",
    "            # Resize the image to 24x44 with black border\n",
    "            char_copy[2:42, 2:22] = char\n",
    "            char_copy[0:2, :] = 0\n",
    "            char_copy[:, 0:2] = 0\n",
    "            char_copy[42:44, :] = 0\n",
    "            char_copy[:, 22:24] = 0\n",
    "\n",
    "            img_res.append(char_copy) #List that stores the character's binary image (unsorted)\n",
    "\n",
    "    #Return characters on ascending order with respect to the x-coordinate (most-left character first)\n",
    "\n",
    "    #arbitrary function that stores sorted list of character indeces\n",
    "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
    "    img_res_copy = []\n",
    "    for idx in indices:\n",
    "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
    "    img_res = np.array(img_res_copy)\n",
    "\n",
    "    return img_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find characters in the resulting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(image) :\n",
    "\n",
    "    # Preprocess cropped license plate image\n",
    "    img_lp = cv2.resize(image, (333, 75))\n",
    "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
    "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
    "\n",
    "    LP_WIDTH = img_binary_lp.shape[0]\n",
    "    LP_HEIGHT = img_binary_lp.shape[1]\n",
    "\n",
    "    # Make borders white\n",
    "    img_binary_lp[0:3,:] = 255\n",
    "    img_binary_lp[:,0:3] = 255\n",
    "    img_binary_lp[72:75,:] = 255\n",
    "    img_binary_lp[:,330:333] = 255\n",
    "\n",
    "    # Estimations of character contours sizes of cropped license plates\n",
    "    dimensions = [LP_WIDTH/6,\n",
    "                       LP_WIDTH/2,\n",
    "                       LP_HEIGHT/10,\n",
    "                       2*LP_HEIGHT/3]\n",
    "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
    "\n",
    "    # Get contours within cropped license plate\n",
    "    char_list = find_contours(dimensions, img_binary_lp)\n",
    "\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing the live image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n",
      "Licence Plate not found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,img = cap.read()\n",
    "    cv2.imshow('Image', img)\n",
    "    plate_img, plate = extract_plate(img)\n",
    "    if plate is None:\n",
    "        print(\"Licence Plate not found\")\n",
    "    else:\n",
    "        cv2.imwrite('licence-plate.jpg', plate)\n",
    "        plate = cv2.imread('licence-plate.jpg')\n",
    "        char = segment_characters(plate)\n",
    "        if len(char) != 0:\n",
    "            cv2.imshow('Image', plate_img)\n",
    "        if len(char) == 10:\n",
    "            cv2.imshow('Image', plate_img)\n",
    "            break\n",
    "    if cv2.waitKey(50) == 13:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('car.jpg')\n",
    "plate_img, plate = extract_plate(img)\n",
    "char = segment_characters(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plate)\n",
    "plt.show()\n",
    "img = cv2.imread('countour_rect.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(char[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3PICNwtZUDAD",
    "outputId": "483eda61-5d3a-4600-ab47-e1cd1bb6058e"
   },
   "outputs": [],
   "source": [
    "def fix_dimension(img): \n",
    "  new_img = np.zeros((28,28,3))\n",
    "  for i in range(3):\n",
    "    new_img[:,:,i] = img\n",
    "  return new_img\n",
    "  \n",
    "def show_results():\n",
    "    dic = {}\n",
    "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    for i,c in enumerate(characters):\n",
    "        dic[i] = c\n",
    "\n",
    "    output = []\n",
    "    for i,ch in enumerate(char): #iterating over the characters\n",
    "        img_ = cv2.resize(ch, (28,28))\n",
    "        img = fix_dimension(img_)\n",
    "        img = img.reshape(1,28,28,3) #preparing image for the model\n",
    "        y_ = model.predict_classes(img)[0] #predicting the class\n",
    "        character = dic[y_] #\n",
    "        output.append(character) #storing the result in a list\n",
    "        \n",
    "    plate_number = ''.join(output)\n",
    "    \n",
    "    return plate_number\n",
    "\n",
    "plate_number = show_results()[:10]\n",
    "char = char[:10]\n",
    "print(\"Licence Plate Number:- \", plate_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "urZpH4YFUDAI",
    "outputId": "6688d92e-0c11-48c7-baa3-1c44b36873aa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i,ch in enumerate(char):\n",
    "    img = cv2.resize(ch, (28,28))\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title(f'predicted: {plate_number[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using API to get details about the vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBboEZgAUDAT"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import json\n",
    "def get_vehicle_info(plate_number):\n",
    "    r = requests.get(\"https://www.regcheck.org.uk/api/reg.asmx/CheckIndia?RegistrationNumber={}&username=Deva12345\".format(str(plate_number)))\n",
    "    print(r)\n",
    "    data = xmltodict.parse(r.content)\n",
    "    jdata = json.dumps(data)\n",
    "    df = json.loads(jdata)\n",
    "    df1 = json.loads(df['Vehicle']['vehicleJson'])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vehicle_info(plate_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ai_powered_license_plate_detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
